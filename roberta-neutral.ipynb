{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"roberta-neutral.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"7yVHgyME4-RL","outputId":"5126be92-d3f1-4843-92a2-164b948a5790","colab_type":"code","executionInfo":{"status":"ok","timestamp":1590504836642,"user_tz":-120,"elapsed":4822,"user":{"displayName":"phu hien nguyen","photoUrl":"","userId":"00373885389146987088"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue May 26 14:53:53 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   68C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QQE4mU-tyxQf","colab_type":"code","outputId":"13dbe67c-8ba6-46ab-8a12-d5b5bacf919c","executionInfo":{"status":"ok","timestamp":1590504836646,"user_tz":-120,"elapsed":4806,"user":{"displayName":"phu hien nguyen","photoUrl":"","userId":"00373885389146987088"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ANl73jUPypXq","colab_type":"code","colab":{}},"source":["# !pip install transformers\n","# !git clone https://github.com/NVIDIA/apex\n","# !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lF2Rw3SbU-zp","colab_type":"code","outputId":"269c417a-5f7d-4320-86bb-b25c77a23ae6","executionInfo":{"status":"ok","timestamp":1590504840410,"user_tz":-120,"elapsed":8065,"user":{"displayName":"phu hien nguyen","photoUrl":"","userId":"00373885389146987088"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import os\n","import re\n","import string\n","import random\n","import numpy as np\n","import pandas as pd\n","import transformers\n","from transformers import *\n","import tokenizers\n","from tqdm import tqdm\n","from nltk import sent_tokenize, download  \n","from apex import amp\n","from albumentations.core.transforms_interface import DualTransform, BasicTransform\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils import data\n","from torch.utils.data import DataLoader, Dataset\n","from torch.autograd import Variable\n","\n","from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","SEED = 123\n","def seed_all(seed_value):\n","    random.seed(seed_value) # Python\n","    np.random.seed(seed_value) # cpu vars\n","    torch.manual_seed(seed_value) # cpu  vars\n","    \n","    if torch.cuda.is_available(): \n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value) # gpu vars\n","        torch.backends.cudnn.deterministic = True  #needed\n","        torch.backends.cudnn.benchmark = False\n","seed_all(SEED)\n","\n","import warnings \n","warnings.filterwarnings('ignore')\n","download('punkt')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"zWOcA6zTVC0H","colab_type":"code","colab":{}},"source":["max_len = 100 \n","train_batch_size = 64\n","valid_batch_size = 100\n","epochs = 8\n","model_pos = \"roberta_pos_\"\n","model_neg = \"roberta_neg_\"\n","model_neu = \"roberta_neu_\"\n","model_path = \"robertabase_\"\n","train_file = \"drive/My Drive/kaggle/Tweet Sentiment Extraction/tweet-sentiment-extraction/train.csv\"\n","new_file = \"drive/My Drive/kaggle/Tweet Sentiment Extraction/tweet-sentiment-extraction/new_data.csv\"\n","test_file = \"drive/My Drive/kaggle/Tweet Sentiment Extraction/tweet-sentiment-extraction/test.csv\"\n","roberta_path = \"drive/My Drive/kaggle/Tweet Sentiment Extraction/Vocab/Roberta\"\n","tokenizer = tokenizers.ByteLevelBPETokenizer(\n","    vocab_file=f\"{roberta_path}/roberta-large-vocab.json\", \n","    merges_file=f\"{roberta_path}/roberta-large-merges.txt\", \n","    lowercase=True,\n","    add_prefix_space=True\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"70aaWzsOVZPU","colab_type":"code","colab":{}},"source":["class NLPTransform(BasicTransform):\n","    \"\"\" Transform for nlp task.\"\"\"\n","    LANGS = {\n","        'en': 'english',\n","        'it': 'italian', \n","        'fr': 'french', \n","        'es': 'spanish',\n","        'tr': 'turkish', \n","        'ru': 'russian',\n","        'pt': 'portuguese'\n","    }\n","\n","    @property\n","    def targets(self):\n","        return {\"data\": self.apply}\n","    \n","    def update_params(self, params, **kwargs):\n","        if hasattr(self, \"interpolation\"):\n","            params[\"interpolation\"] = self.interpolation\n","        if hasattr(self, \"fill_value\"):\n","            params[\"fill_value\"] = self.fill_value\n","        return params\n","\n","    def get_sentences(self, text, lang='en'):\n","        return sent_tokenize(text, self.LANGS.get(lang, 'english'))\n","\n","class ShuffleSentencesTransform(NLPTransform):\n","    \"\"\" Do shuffle by sentence \"\"\"\n","    def __init__(self, always_apply=False, p=0.5):\n","        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n","\n","    def apply(self, data, **params):\n","        text, lang = data\n","        sentences = self.get_sentences(text, lang)\n","        random.shuffle(sentences)\n","        return ' '.join(sentences), lang\n","\n","transform = ShuffleSentencesTransform(p=1.0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkmkizK5ySC7","colab_type":"code","colab":{}},"source":["def binary_cross_entropy(inputs, target, weight=None, reduction='mean', smooth_eps=None, from_logits=False):\n","    \"\"\"cross entropy loss, with support for label smoothing https://arxiv.org/abs/1512.00567\"\"\"\n","    smooth_eps = smooth_eps or 0\n","    if smooth_eps > 0:\n","        target = target.float()\n","        target.add_(smooth_eps).div_(2.)\n","    if from_logits:\n","        return F.binary_cross_entropy_with_logits(inputs, target, weight=weight, reduction=reduction)\n","    else:\n","        return F.binary_cross_entropy(inputs, target, weight=weight, reduction=reduction)\n","\n","\n","def binary_cross_entropy_with_logits(inputs, target, weight=None, reduction='mean', smooth_eps=None, from_logits=True):\n","    return binary_cross_entropy(inputs, target, weight, reduction, smooth_eps, from_logits)\n","\n","\n","class BCELoss(nn.BCELoss):\n","    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean', smooth_eps=None, from_logits=False):\n","        super(BCELoss, self).__init__(weight, size_average, reduce, reduction)\n","        self.smooth_eps = smooth_eps\n","        self.from_logits = from_logits\n","\n","    def forward(self, input, target):\n","        return binary_cross_entropy(input, target,\n","                                    weight=self.weight, reduction=self.reduction,\n","                                    smooth_eps=self.smooth_eps, from_logits=self.from_logits)\n","\n","\n","class BCEWithLogitsLoss(BCELoss):\n","    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean', smooth_eps=None, from_logits=True):\n","        super(BCEWithLogitsLoss, self).__init__(weight, size_average,\n","                                                reduce, reduction, smooth_eps=smooth_eps, from_logits=from_logits)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkppAVoNySC9","colab_type":"code","colab":{}},"source":["class AverageMeter:\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def loss_fn(start_logits, end_logits, start_positions, end_positions):\n","    start_loss = BCEWithLogitsLoss(smooth_eps=None)(start_logits, start_positions) \n","    end_loss = BCEWithLogitsLoss(smooth_eps=None)(end_logits, end_positions)\n","    total_loss = (start_loss + end_loss) #+ F.smooth_l1_loss(logits, span_logits)\n","#     dis_loss =  dist_loss(start_logits, end_logits, start_positions, end_positions, device)\n","    # len_loss = nn.MSELoss()(length, length_)/max_len\n","    return total_loss\n","\n","def jaccard(str1, str2): \n","    a = set(str1.lower().split()) \n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH-64ZxoSHJp","colab_type":"code","colab":{}},"source":["def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n","  \n","    tweet = \" \" + \" \".join(str(tweet).split())\n","    selected_text = \" \" + \" \".join(str(selected_text).split())\n","\n","    len_st = len(selected_text) - 1\n","    idx0 = None\n","    idx1 = None\n","\n","    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n","        if \" \" + tweet[ind: ind+len_st] == selected_text:\n","            idx0 = ind\n","            idx1 = ind + len_st - 1\n","            break\n","\n","    char_targets = [0] * len(tweet)\n","    if idx0 != None and idx1 != None:\n","        for ct in range(idx0, idx1 + 1):\n","            char_targets[ct] = 1\n","    \n","    tok_tweet = tokenizer.encode(tweet)\n","    input_ids_orig = tok_tweet.ids\n","    tweet_offsets = tok_tweet.offsets\n","    \n","    target_idx = []\n","    for j, (offset1, offset2) in enumerate(tweet_offsets):\n","        if sum(char_targets[offset1: offset2]) > 0:\n","            target_idx.append(j)\n","    \n","    targets_start = target_idx[0]\n","    targets_end = target_idx[-1]\n","    \n","    target_logits = [0]*(targets_start+4) + [1]*len(target_idx) + [0]*(max_len-(targets_start+4)-len(target_idx))\n","    targets_start_logits = [0]*len(target_logits)\n","    targets_end_logits = [0]*len(target_logits) \n","\n","    nonzero = np.nonzero(target_logits)[0]\n","    if len(nonzero) > 0:\n","        targets_start_logits[nonzero[0]] = 1\n","        targets_end_logits[nonzero[-1]] = 1\n","\n","    sentiment_id = {\n","        'positive': 1313,\n","        'negative': 2430,\n","        'neutral': 7974\n","    }\n","\n","    input_ids = [0]+[sentiment_id[sentiment]]+[2]+[2]+input_ids_orig+[2]\n","    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n","    mask = [1] * len(token_type_ids)\n","    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n","    targets_start += 4\n","    targets_end += 4\n","\n","    padding_length = max_len - len(input_ids)\n","    if padding_length > 0:\n","        input_ids = input_ids + ([1] * padding_length)\n","        mask = mask + ([0] * padding_length)\n","        token_type_ids = token_type_ids + ([0] * padding_length)\n","        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n","\n","    targets = targets_end - targets_start\n","    \n","    if sentiment == 'positive':\n","        sentiment_vector = [1,0,0]\n","    elif sentiment == 'negative':\n","        sentiment_vector = [0,0,1]\n","    else:\n","        sentiment_vector = [0,1,0]\n","\n","    return {\n","        'ids': input_ids,\n","        'mask': mask,\n","        'token_type_ids': token_type_ids,\n","        'targets_start': targets_start_logits,\n","        'targets_end': targets_end_logits,\n","        'targets_start_index': targets_start,\n","        'targets_end_index': targets_end,\n","        'targets': target_logits,\n","        'orig_tweet': tweet,\n","        'orig_selected': selected_text,\n","        'sentiment': sentiment,\n","        'offsets': tweet_offsets,\n","        'sentiment_vector':sentiment_vector,\n","        'span_target':targets\n","    }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WU8JXIMjXtwT","colab_type":"code","colab":{}},"source":["class TweetDataset(Dataset):\n","    def __init__(self, tweet, sentiment, selected_text):\n","        self.tweet = tweet\n","        self.sentiment = sentiment\n","        self.selected_text = selected_text\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","    \n","    def __len__(self):\n","        return len(self.tweet)\n","\n","    def __getitem__(self, item):\n","        data = process_data(\n","            self.tweet[item], \n","            self.selected_text[item], \n","            self.sentiment[item],\n","            self.tokenizer,\n","            self.max_len,\n","        )\n","\n","        return {\n","            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n","            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n","            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n","            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.float),\n","            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.float),\n","            'targets_start_index': torch.tensor(data[\"targets_start_index\"], dtype=torch.long),\n","            'targets_end_index': torch.tensor(data[\"targets_end_index\"], dtype=torch.long),\n","            'targets': torch.tensor(data[\"targets\"], dtype=torch.float),\n","            'orig_tweet': data[\"orig_tweet\"],\n","            'orig_selected': data[\"orig_selected\"],\n","            'sentiment': data[\"sentiment\"],\n","            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long),\n","            'sentiment_vector': torch.tensor(data[\"sentiment_vector\"], dtype=torch.float),\n","            'span_target':torch.tensor(data[\"span_target\"], dtype=torch.float)\n","        }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VoULgPhySDD","colab_type":"code","colab":{}},"source":["# class TweetRobertaBase(BertPreTrainedModel):\n","#     def __init__(self, conf):\n","#         super(TweetRobertaBase, self).__init__(conf)\n","#         self.roberta = RobertaModel.from_pretrained('roberta-base', config=conf)\n","#         self.drop_out = nn.Dropout(0.3)\n","#         self.l0 = nn.Linear(768, 2)\n","#         self.l1 = nn.Linear(768*2, 1)\n","    \n","#     def forward(self, ids, mask, token_type_ids):\n","#         _, _, hidden_outputs = self.roberta(\n","#             ids,\n","#             attention_mask=mask,\n","#             token_type_ids=token_type_ids\n","#         )\n","        \n","#         sequence_output = torch.stack(hidden_outputs[-4:]).mean(0)\n","# #         sequence_output = hidden_outputs[-2]\n","#         out = self.drop_out(sequence_output)\n","#         logits = self.l0(out)\n","#         start_logits, end_logits = logits.split(1, dim=-1)\n","#         start_logits = start_logits.squeeze(-1)\n","#         end_logits = end_logits.squeeze(-1)\n","\n","#         avg_pool = torch.mean(sequence_output, 1)\n","#         max_pool, _ = torch.max(sequence_output, 1)\n","#         long_logits = torch.cat((max_pool, avg_pool), 1)\n","#         long_logits = self.drop_out(long_logits)\n","#         long_logits = self.l1(long_logits).squeeze(-1)  \n","        \n","#         return start_logits, end_logits, long_logits"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H56JL5XwVgoW","colab_type":"code","colab":{}},"source":["class TweetRobertaBase(BertPreTrainedModel):\n","    def __init__(self, conf):\n","        super(TweetRobertaBase, self).__init__(conf)\n","        self.config = conf\n","        self.roberta = RobertaModel.from_pretrained('roberta-base', config=self.config)\n","        self.lstm_units = 768\n","        self.num_recurrent_layers = 1\n","        self.bidirectional = True\n","\n","        self.lstm = nn.LSTM(input_size=self.config.hidden_size*2,\n","                            hidden_size=self.lstm_units,\n","                            num_layers=self.num_recurrent_layers,\n","                            bidirectional=self.bidirectional,\n","                            batch_first=True)\n","        \n","        self.dropout = nn.Dropout(0.2)  \n","        self.l0 = nn.Linear(self.config.hidden_size*2, 2)\n","        self.l1 = nn.Linear(self.config.hidden_size*4, 3)\n","    \n","    def forward(self, ids, mask, token_type_ids):\n","        sequence_output, _, hidden_outputs = self.roberta(\n","            ids,\n","            attention_mask=mask,\n","            token_type_ids=token_type_ids\n","        )\n","        \n","        # sequence_output = torch.stack(hidden_outputs[-2:]).mean(0)\n","        sequence_output = torch.cat(tuple([hidden_outputs[i] for i in [-1, -2]]), dim=-1)\n","\n","        if self.bidirectional:\n","            n = 2\n","        else: n = 1\n","\n","        h0 = Variable(torch.zeros(self.num_recurrent_layers * n,       # (L * 2 OR L, B, H)\n","                                  ids.shape[0],\n","                                  self.lstm_units)).cuda()\n","        c0 = Variable(torch.zeros(self.num_recurrent_layers * n,        # (L * 2 OR L, B, H)\n","                                  ids.shape[0],\n","                                  self.lstm_units)).cuda()\n","        \n","        output, _ = self.lstm(sequence_output, (h0, c0))\n","        output = self.dropout(output)\n","\n","        logits = self.l0(output)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","\n","        # avg_pool = torch.mean(output, 1)\n","        # max_pool, _ = torch.max(output, 1)\n","        # long_logits = torch.cat((max_pool, avg_pool), 1)\n","        # long_logits = self.l1(long_logits)\n","\n","        return start_logits, end_logits"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SK-OigPeYV-","colab_type":"code","colab":{}},"source":["cdf_threshold = 0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2WlDtQnPVj-x","colab_type":"code","colab":{}},"source":["def train_model(model, data_loader, optimizer, scheduler, device):\n","    \n","    model.train()\n","    losses = AverageMeter()\n","    jaccards = AverageMeter()\n","    jaccards_neu = AverageMeter()\n","    jaccards_pos = AverageMeter()\n","    jaccards_neg = AverageMeter()\n","\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    \n","    for bi, d in enumerate(tk0):\n","\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        targets_start = d[\"targets_start\"]\n","        targets_end = d[\"targets_end\"]\n","        sentiment = d[\"sentiment\"]\n","        orig_selected = d[\"orig_selected\"]\n","        orig_tweet = d[\"orig_tweet\"]\n","        targets_start_index = d[\"targets_start_index\"]\n","        targets_end_index = d[\"targets_end_index\"]\n","        offsets = d[\"offsets\"]\n","        targets = d[\"sentiment_vector\"]\n","        span_targets = d[\"span_target\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets_start = targets_start.to(device, dtype=torch.float)\n","        targets_end = targets_end.to(device, dtype=torch.float)\n","        targets_start_index = targets_start_index.to(device, dtype=torch.long)\n","        targets_end_index = targets_end_index.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.float)\n","        span_targets = span_targets.to(device, dtype=torch.float)\n","\n","        model.zero_grad()\n","        outputs_start, outputs_end = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids,\n","        )\n","\n","        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)       \n","        with amp.scale_loss(loss, optimizer) as scaled_loss:\n","            scaled_loss.backward() \n","        optimizer.step()\n","        scheduler.step()\n","        \n","        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","\n","        jaccard_scores = []\n","        jaccard_scores_neu = []\n","        jaccard_scores_pos = []\n","        jaccard_scores_neg = []\n","\n","        for px, tweet in enumerate(orig_tweet):\n","            selected_tweet = orig_selected[px]\n","            tweet_sentiment = sentiment[px]\n","            jaccard_score, jaccard_neu_score, jaccard_pos_score, jaccard_neg_score, _ = calculate_jaccard_score(\n","                                                                                                          original_tweet=tweet,\n","                                                                                                          target_string=selected_tweet,\n","                                                                                                          sentiment_val=tweet_sentiment,\n","                                                                                                          # idx_start=np.argmax(outputs_start[px, :]),\n","                                                                                                          # idx_end=np.argmax(outputs_end[px, :]),\n","                                                                                                          idx_start=np.where(outputs_start[px, :].cumsum(axis = 0) > cdf_threshold)[0].min(),\n","                                                                                                          idx_end=np.where(outputs_end[px, :][::-1].cumsum(axis = 0)[::-1] > cdf_threshold)[0].max(),\n","                                                                                                          offsets=offsets[px]\n","                                                                                                      )\n","            jaccard_scores.append(jaccard_score)\n","            if jaccard_neu_score is not None:\n","                jaccard_scores_neu.append(jaccard_neu_score)\n","            if jaccard_pos_score is not None:\n","                jaccard_scores_pos.append(jaccard_pos_score)\n","            if jaccard_neg_score is not None:\n","                jaccard_scores_neg.append(jaccard_neg_score)\n","\n","        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n","        jaccards_neu.update(np.mean(jaccard_scores_neu), ids.size(0))\n","        jaccards_pos.update(np.mean(jaccard_scores_pos), ids.size(0))\n","        jaccards_neg.update(np.mean(jaccard_scores_neg), ids.size(0))\n","        losses.update(loss.item(), ids.size(0))\n","        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg, jaccard_neu=jaccards_neu.avg, jaccard_pos=jaccards_pos.avg, jaccard_neg=jaccards_neg.avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_EGQwiqVszE","colab_type":"code","colab":{}},"source":["def calculate_jaccard_score(original_tweet, target_string, sentiment_val, idx_start,\n","                            idx_end, offsets, verbose=False):\n","    \n","    if idx_end < idx_start:\n","        idx_end = idx_start\n","    \n","    filtered_output  = \"\"\n","    for ix in range(idx_start, idx_end + 1):\n","        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n","        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n","            filtered_output += \" \"\n","\n","    # if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n","    #     filtered_output = original_tweet\n","    # elif sentiment_val == \"positive\" or sentiment_val == \"negative\":\n","    #     word_tokens = word_tokenize(filtered_output)  \n","    #     filtered_output = ' '.join([w for w in word_tokens if not w in stop_words]) \n","\n","    jac = jaccard(target_string.strip(), filtered_output.strip())\n","    jac_neu, jac_pos, jac_neg = None, None, None\n","    if sentiment_val == \"neutral\":\n","        jac_neu = jaccard(target_string.strip(), filtered_output.strip())\n","    elif sentiment_val == \"positive\":\n","        jac_pos = jaccard(target_string.strip(), filtered_output.strip())\n","    elif sentiment_val == \"negative\":\n","        jac_neg = jaccard(target_string.strip(), filtered_output.strip())\n","\n","    return jac, jac_neu, jac_pos, jac_neg, filtered_output\n","\n","\n","def eval_model(model, data_loader, device):\n","    \n","    model.eval()\n","    losses = AverageMeter()\n","    jaccards = AverageMeter()\n","    jaccards_neu = AverageMeter()\n","    jaccards_pos = AverageMeter()\n","    jaccards_neg = AverageMeter()\n","\n","    out_strings = []\n","\n","    with torch.no_grad():\n","        tk0 = tqdm(data_loader, total=len(data_loader))\n","        for bi, d in enumerate(tk0):\n","            ids = d[\"ids\"]\n","            token_type_ids = d[\"token_type_ids\"]\n","            mask = d[\"mask\"]\n","            sentiment = d[\"sentiment\"]\n","            orig_selected = d[\"orig_selected\"]\n","            orig_tweet = d[\"orig_tweet\"]\n","            targets_start = d[\"targets_start\"]\n","            targets_end = d[\"targets_end\"]\n","            targets_start_index = d[\"targets_start_index\"]\n","            targets_end_index = d[\"targets_end_index\"]\n","            offsets = d[\"offsets\"].numpy()\n","            targets = d[\"sentiment_vector\"]\n","            span_targets = d[\"span_target\"]\n","            \n","            ids = ids.to(device, dtype=torch.long)\n","            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets_start = targets_start.to(device, dtype=torch.float)\n","            targets_end = targets_end.to(device, dtype=torch.float)\n","            targets_start_index = targets_start_index.to(device, dtype=torch.long)\n","            targets_end_index = targets_end_index.to(device, dtype=torch.long)\n","            targets = targets.to(device, dtype=torch.float)\n","            span_targets = span_targets.to(device, dtype=torch.float)\n","            \n","            outputs_start, outputs_end = model(\n","                ids=ids,\n","                mask=mask,\n","                token_type_ids=token_type_ids\n","            )\n","            \n","            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)   \n","            outputs_start = torch.softmax(outputs_start, dim = 1).cpu().detach().numpy()\n","            outputs_end = torch.softmax(outputs_end, dim = 1).cpu().detach().numpy()\n","\n","            jaccard_scores = []\n","            jaccard_scores_neu = []\n","            jaccard_scores_pos = []\n","            jaccard_scores_neg = []\n","            \n","            for px, tweet in enumerate(orig_tweet):\n","                selected_tweet = orig_selected[px]\n","                tweet_sentiment = sentiment[px]\n","                jaccard_score, jaccard_neu_score, jaccard_pos_score, jaccard_neg_score, _ = calculate_jaccard_score(\n","                                                                                                              original_tweet=tweet,\n","                                                                                                              target_string=selected_tweet,\n","                                                                                                              sentiment_val=tweet_sentiment,\n","                                                                                                              # idx_start=np.argmax(outputs_start[px, :]),\n","                                                                                                              # idx_end=np.argmax(outputs_end[px, :]),\n","                                                                                                              idx_start=np.where(outputs_start[px, :].cumsum(axis = 0) > cdf_threshold)[0].min(),\n","                                                                                                              idx_end=np.where(outputs_end[px, :][::-1].cumsum(axis = 0)[::-1] > cdf_threshold)[0].max(),\n","                                                                                                              offsets=offsets[px]\n","                                                                                                          )\n","                jaccard_scores.append(jaccard_score)\n","                if jaccard_neu_score is not None:\n","                    jaccard_scores_neu.append(jaccard_neu_score)\n","                if jaccard_pos_score is not None:\n","                    jaccard_scores_pos.append(jaccard_pos_score)\n","                if jaccard_neg_score is not None:\n","                    jaccard_scores_neg.append(jaccard_neg_score)\n","                out_strings.append(_)\n","\n","            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n","            jaccards_neu.update(np.mean(jaccard_scores_neu), ids.size(0))\n","            jaccards_pos.update(np.mean(jaccard_scores_pos), ids.size(0))\n","            jaccards_neg.update(np.mean(jaccard_scores_neg), ids.size(0))\n","            losses.update(loss.item(), ids.size(0))\n","            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg, jaccard_neu=jaccards_neu.avg, jaccard_pos=jaccards_pos.avg, jaccard_neg=jaccards_neg.avg)\n","                   \n","    print(f\"Jaccard = {jaccards.avg}\")\n","    print(f\"Jaccard_neu = {jaccards_neu.avg}\")\n","    print(f\"Jaccard_pos = {jaccards_pos.avg}\")\n","    print(f\"Jaccard_neg = {jaccards_neg.avg}\")\n","    return jaccards.avg, jaccards_neu.avg, jaccards_neg.avg, jaccards_pos.avg, out_strings"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tK5ON-BIySDL","colab_type":"code","colab":{}},"source":["train = pd.read_csv(train_file).dropna().reset_index(drop=True)\n","# orig_columns = train.columns[1:]\n","# train['len_text'] = train.text.apply(lambda x: len(x.split()))\n","# train['len_sel'] = train.selected_text.apply(lambda x: len(x.split()))\n","# train['len_ratio'] = train['len_sel']/train['len_text']\n","# train['len_text_tokenize'] = train.text.apply(lambda x: len(sent_tokenize(x)))\n","\n","# extended_train = train.loc[(train['len_text_tokenize'] > 1) & (train['len_ratio'] < 0.5)].reset_index(drop = True)\n","# extended_train['text'] = extended_train.text.apply(lambda x: transform(data=(x.strip(), 'en'))['data'][0])\n","\n","# train['target'] = 0\n","# train.loc[train['text'].str.strip() == train['selected_text'].str.strip(), 'target'] = 1\n","# extended_train_1 = train.loc[(train['target'] == 1) & (train['len_text_tokenize'] > 1)].reset_index(drop = True)\n","# extended_train_1['text'] = extended_train_1.text.apply(lambda x: transform(data=(x.strip(), 'en'))['data'][0])\n","# extended_train_1['selected_text'] = extended_train_1['text']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSfP7D_cySDN","colab_type":"code","colab":{}},"source":["# fail_index = []\n","# for i in range(len(extended_train)):\n","#     try:\n","#         process_data(extended_train.text[i], extended_train.selected_text[i], extended_train.sentiment[i], tokenizer, max_len)\n","#     except:\n","#         fail_index.append(i)\n","# extended_train = extended_train.drop(fail_index)\n","\n","# train = pd.concat([train, extended_train_1], axis=0)\n","# train = train[orig_columns]\n","# train = train.sample(frac=1).reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEWBfmSRVwwj","outputId":"7169cd15-d8d6-44a2-8424-8df476a6eed2","colab_type":"code","executionInfo":{"status":"ok","timestamp":1590511838671,"user_tz":-120,"elapsed":7001762,"user":{"displayName":"phu hien nguyen","photoUrl":"","userId":"00373885389146987088"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model_config = RobertaConfig.from_pretrained(\"roberta-base\")\n","model_config.num_labels = 2\n","model_config.output_hidden_states = True\n","\n","all_scores, score_neu, score_neg, score_pos = [], [], [], []\n","predictions = ['']*len(train)\n","    \n","kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n","for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train['sentiment'])):\n","    print(f'Fold no {fold+1}:')\n","        \n","    x_train = train.iloc[tr_ind].reset_index(drop=True)\n","    x_val = train.iloc[val_ind].reset_index(drop=True)        \n","\n","    train_dataset = TweetDataset(tweet = x_train.text.values,\n","                                sentiment = x_train.sentiment.values,\n","                                selected_text = x_train.selected_text.values)\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                              batch_size=train_batch_size,\n","                                              num_workers=4)\n","\n","    valid_dataset = TweetDataset(tweet = x_val.text.values,\n","                                sentiment = x_val.sentiment.values,\n","                                selected_text = x_val.selected_text.values)\n","\n","    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n","                                              batch_size=valid_batch_size,\n","                                              num_workers=1)\n","\n","    device = torch.device(\"cuda\")\n","    model = TweetRobertaBase(conf=model_config)\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","    ]\n","\n","    num_train_steps = int(len(x_train) / train_batch_size * epochs)\n","    optimizer = AdamW(optimizer_parameters, lr=4e-5)\n","    \n","#     scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n","#         optimizer,\n","#         num_warmup_steps=0,\n","#         num_training_steps=num_train_steps,\n","#     )\n","\n","    scheduler = get_cosine_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=0,\n","        num_training_steps=num_train_steps\n","    )\n","\n","    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", verbosity = 0)\n","\n","    print(\"Training....\")\n","    best_jaccard, best_neu, best_neg, best_pos = 0, 0, 0, 0\n","    for epoch in range(epochs):\n","        train_model(model, train_loader, optimizer, scheduler, device)\n","        jaccard_score, jaccard_neu, jaccard_neg, jaccard_pos, out_strings = eval_model(model, valid_loader, device)\n","              \n","        if jaccard_neu > best_neu:\n","            best_neu = jaccard_neu\n","            print(f'Saving neutral model with jaccard of {best_neu}!')\n","            torch.save(model.state_dict(), model_neu+str(fold)+'.bin')\n","        if jaccard_neg > best_neg:\n","            best_neg = jaccard_neg\n","            print(f'Saving negative model with jaccard of {best_neg}!')\n","            torch.save(model.state_dict(), model_neg+str(fold)+'.bin')\n","        if jaccard_pos > best_pos:\n","            best_pos = jaccard_pos\n","            print(f'Saving positive model with jaccard of {best_pos}!')\n","            torch.save(model.state_dict(), model_pos+str(fold)+'.bin')\n","        if jaccard_score > best_jaccard:\n","            best_jaccard = jaccard_score\n","            # torch.save(model.state_dict(),'model_'+str(fold)+'.bin')\n","            for i in range(len(val_ind)):\n","                predictions[val_ind[i]] = out_strings[i]\n","                \n","    all_scores.append(best_jaccard)\n","    score_neu.append(best_neu)\n","    score_neg.append(best_neg)\n","    score_pos.append(best_pos)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Fold no 1:\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training....\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.19it/s, jaccard=0.485, jaccard_neg=0.325, jaccard_neu=0.723, jaccard_pos=0.319, loss=0.0678]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.677, jaccard_neg=0.483, jaccard_neu=0.973, jaccard_pos=0.475, loss=0.0303]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6772624852257336\n","Jaccard_neu = 0.9727873033031826\n","Jaccard_pos = 0.4752663140076805\n","Jaccard_neg = 0.48295119097050887\n","Saving neutral model with jaccard of 0.9727873033031826!\n","Saving negative model with jaccard of 0.48295119097050887!\n","Saving positive model with jaccard of 0.4752663140076805!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:36<00:00,  2.20it/s, jaccard=0.695, jaccard_neg=0.498, jaccard_neu=0.976, jaccard_pos=0.51, loss=0.0277]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.695, jaccard_neg=0.513, jaccard_neu=0.973, jaccard_pos=0.501, loss=0.0281]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6947501925821513\n","Jaccard_neu = 0.9727873033031826\n","Jaccard_pos = 0.5010411655326238\n","Jaccard_neg = 0.5130893372166574\n","Saving negative model with jaccard of 0.5130893372166574!\n","Saving positive model with jaccard of 0.5010411655326238!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.717, jaccard_neg=0.544, jaccard_neu=0.976, jaccard_pos=0.538, loss=0.025]\n","100%|██████████| 55/55 [00:12<00:00,  4.38it/s, jaccard=0.7, jaccard_neg=0.52, jaccard_neu=0.973, jaccard_pos=0.513, loss=0.0283]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7004638291577134\n","Jaccard_neu = 0.9728362099062778\n","Jaccard_pos = 0.5125705160799655\n","Jaccard_neg = 0.5199653571973446\n","Saving neutral model with jaccard of 0.9728362099062778!\n","Saving negative model with jaccard of 0.5199653571973446!\n","Saving positive model with jaccard of 0.5125705160799655!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.738, jaccard_neg=0.58, jaccard_neu=0.977, jaccard_pos=0.574, loss=0.0231]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.702, jaccard_neg=0.523, jaccard_neu=0.973, jaccard_pos=0.517, loss=0.0286]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7021373957937708\n","Jaccard_neu = 0.9728016350963907\n","Jaccard_pos = 0.5165439472309954\n","Jaccard_neg = 0.5229223684472031\n","Saving negative model with jaccard of 0.5229223684472031!\n","Saving positive model with jaccard of 0.5165439472309954!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.758, jaccard_neg=0.611, jaccard_neu=0.977, jaccard_pos=0.606, loss=0.0213]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.704, jaccard_neg=0.53, jaccard_neu=0.973, jaccard_pos=0.516, loss=0.0291]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7042680416445792\n","Jaccard_neu = 0.9731274241987712\n","Jaccard_pos = 0.5162507820721332\n","Jaccard_neg = 0.5295553918361091\n","Saving neutral model with jaccard of 0.9731274241987712!\n","Saving negative model with jaccard of 0.5295553918361091!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.775, jaccard_neg=0.642, jaccard_neu=0.979, jaccard_pos=0.631, loss=0.0199]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.701, jaccard_neg=0.525, jaccard_neu=0.973, jaccard_pos=0.512, loss=0.0291]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7011528421052452\n","Jaccard_neu = 0.9725648162609576\n","Jaccard_pos = 0.5120530254770603\n","Jaccard_neg = 0.5250801214846132\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.788, jaccard_neg=0.664, jaccard_neu=0.979, jaccard_pos=0.652, loss=0.0189]\n","100%|██████████| 55/55 [00:12<00:00,  4.36it/s, jaccard=0.701, jaccard_neg=0.521, jaccard_neu=0.972, jaccard_pos=0.513, loss=0.0301]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7006374381349475\n","Jaccard_neu = 0.9723299881548013\n","Jaccard_pos = 0.512894486439081\n","Jaccard_neg = 0.5214325221896945\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.794, jaccard_neg=0.673, jaccard_neu=0.98, jaccard_pos=0.662, loss=0.0183]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.7, jaccard_neg=0.52, jaccard_neu=0.972, jaccard_pos=0.512, loss=0.0302]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6997390208602278\n","Jaccard_neu = 0.9723146805041771\n","Jaccard_pos = 0.5118512143481494\n","Jaccard_neg = 0.5204496531887285\n","Fold no 2:\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training....\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.18it/s, jaccard=0.494, jaccard_neg=0.324, jaccard_neu=0.746, jaccard_pos=0.319, loss=0.0661]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.684, jaccard_neg=0.491, jaccard_neu=0.975, jaccard_pos=0.482, loss=0.0289]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6842724888393819\n","Jaccard_neu = 0.9750525690816386\n","Jaccard_pos = 0.4823591493958894\n","Jaccard_neg = 0.49137118204018077\n","Saving neutral model with jaccard of 0.9750525690816386!\n","Saving negative model with jaccard of 0.49137118204018077!\n","Saving positive model with jaccard of 0.4823591493958894!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.18it/s, jaccard=0.687, jaccard_neg=0.49, jaccard_neu=0.975, jaccard_pos=0.493, loss=0.0282]\n","100%|██████████| 55/55 [00:12<00:00,  4.38it/s, jaccard=0.707, jaccard_neg=0.527, jaccard_neu=0.975, jaccard_pos=0.521, loss=0.0262]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7066958475821361\n","Jaccard_neu = 0.9749351119704465\n","Jaccard_pos = 0.5211357349775777\n","Jaccard_neg = 0.5265451773207381\n","Saving negative model with jaccard of 0.5265451773207381!\n","Saving positive model with jaccard of 0.5211357349775777!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.19it/s, jaccard=0.71, jaccard_neg=0.53, jaccard_neu=0.975, jaccard_pos=0.529, loss=0.0254]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.704, jaccard_neg=0.516, jaccard_neu=0.975, jaccard_pos=0.52, loss=0.0261]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7038289383915258\n","Jaccard_neu = 0.9749276258593632\n","Jaccard_pos = 0.5198557982953738\n","Jaccard_neg = 0.5162687826093073\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:36<00:00,  2.20it/s, jaccard=0.728, jaccard_neg=0.565, jaccard_neu=0.976, jaccard_pos=0.554, loss=0.0238]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.711, jaccard_neg=0.529, jaccard_neu=0.975, jaccard_pos=0.53, loss=0.0262]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7106379187504039\n","Jaccard_neu = 0.9746668444570578\n","Jaccard_pos = 0.53024721852384\n","Jaccard_neg = 0.5294075007079857\n","Saving negative model with jaccard of 0.5294075007079857!\n","Saving positive model with jaccard of 0.53024721852384!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:36<00:00,  2.20it/s, jaccard=0.742, jaccard_neg=0.585, jaccard_neu=0.976, jaccard_pos=0.581, loss=0.0226]\n","100%|██████████| 55/55 [00:12<00:00,  4.36it/s, jaccard=0.71, jaccard_neg=0.531, jaccard_neu=0.974, jaccard_pos=0.525, loss=0.0265]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.709558174009492\n","Jaccard_neu = 0.9744227007925258\n","Jaccard_pos = 0.5248820883426603\n","Jaccard_neg = 0.5311770650198643\n","Saving negative model with jaccard of 0.5311770650198643!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:36<00:00,  2.20it/s, jaccard=0.759, jaccard_neg=0.619, jaccard_neu=0.978, jaccard_pos=0.602, loss=0.021]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.709, jaccard_neg=0.526, jaccard_neu=0.975, jaccard_pos=0.528, loss=0.0269]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.709219301292692\n","Jaccard_neu = 0.974537050269313\n","Jaccard_pos = 0.52823111786608\n","Jaccard_neg = 0.5259231713911844\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.77, jaccard_neg=0.637, jaccard_neu=0.978, jaccard_pos=0.62, loss=0.0201]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.708, jaccard_neg=0.524, jaccard_neu=0.974, jaccard_pos=0.528, loss=0.0274]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7083778751226549\n","Jaccard_neu = 0.9740514333652447\n","Jaccard_pos = 0.5283860367832218\n","Jaccard_neg = 0.5244955445955869\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:35<00:00,  2.21it/s, jaccard=0.774, jaccard_neg=0.647, jaccard_neu=0.979, jaccard_pos=0.624, loss=0.0196]\n","100%|██████████| 55/55 [00:12<00:00,  4.39it/s, jaccard=0.71, jaccard_neg=0.525, jaccard_neu=0.974, jaccard_pos=0.532, loss=0.0276]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7096158388346528\n","Jaccard_neu = 0.9741914371586676\n","Jaccard_pos = 0.5315587470878916\n","Jaccard_neg = 0.525147592296121\n","Saving positive model with jaccard of 0.5315587470878916!\n","Fold no 3:\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training....\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:39<00:00,  2.16it/s, jaccard=0.476, jaccard_neg=0.316, jaccard_neu=0.715, jaccard_pos=0.31, loss=0.0672]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.687, jaccard_neg=0.498, jaccard_neu=0.975, jaccard_pos=0.485, loss=0.0284]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6866634734765023\n","Jaccard_neu = 0.9754979523559492\n","Jaccard_pos = 0.4847853268406725\n","Jaccard_neg = 0.4979796087823672\n","Saving neutral model with jaccard of 0.9754979523559492!\n","Saving negative model with jaccard of 0.4979796087823672!\n","Saving positive model with jaccard of 0.4847853268406725!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.18it/s, jaccard=0.693, jaccard_neg=0.496, jaccard_neu=0.976, jaccard_pos=0.505, loss=0.0275]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.702, jaccard_neg=0.519, jaccard_neu=0.976, jaccard_pos=0.514, loss=0.0263]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7017159779191593\n","Jaccard_neu = 0.9755996739640089\n","Jaccard_pos = 0.514419823809611\n","Jaccard_neg = 0.5187765722369276\n","Saving neutral model with jaccard of 0.9755996739640089!\n","Saving negative model with jaccard of 0.5187765722369276!\n","Saving positive model with jaccard of 0.514419823809611!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.18it/s, jaccard=0.714, jaccard_neg=0.542, jaccard_neu=0.976, jaccard_pos=0.53, loss=0.0251]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.704, jaccard_neg=0.528, jaccard_neu=0.976, jaccard_pos=0.511, loss=0.0267]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7039187304364545\n","Jaccard_neu = 0.9761117968191045\n","Jaccard_pos = 0.5111613800747574\n","Jaccard_neg = 0.52753671077199\n","Saving neutral model with jaccard of 0.9761117968191045!\n","Saving negative model with jaccard of 0.52753671077199!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.19it/s, jaccard=0.732, jaccard_neg=0.569, jaccard_neu=0.976, jaccard_pos=0.562, loss=0.0234]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.706, jaccard_neg=0.531, jaccard_neu=0.976, jaccard_pos=0.515, loss=0.0263]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7062949624224804\n","Jaccard_neu = 0.9759769691924692\n","Jaccard_pos = 0.5149157673868623\n","Jaccard_neg = 0.5311076150982212\n","Saving negative model with jaccard of 0.5311076150982212!\n","Saving positive model with jaccard of 0.5149157673868623!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.19it/s, jaccard=0.748, jaccard_neg=0.6, jaccard_neu=0.976, jaccard_pos=0.585, loss=0.022]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.706, jaccard_neg=0.532, jaccard_neu=0.975, jaccard_pos=0.516, loss=0.0267]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.705918499316856\n","Jaccard_neu = 0.974770108637632\n","Jaccard_pos = 0.5156373421832081\n","Jaccard_neg = 0.5321096654464132\n","Saving negative model with jaccard of 0.5321096654464132!\n","Saving positive model with jaccard of 0.5156373421832081!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:36<00:00,  2.19it/s, jaccard=0.766, jaccard_neg=0.636, jaccard_neu=0.977, jaccard_pos=0.612, loss=0.0205]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.704, jaccard_neg=0.527, jaccard_neu=0.974, jaccard_pos=0.514, loss=0.0277]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7038889080506824\n","Jaccard_neu = 0.9739378094193774\n","Jaccard_pos = 0.5142340144873985\n","Jaccard_neg = 0.5273991270330532\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.19it/s, jaccard=0.78, jaccard_neg=0.657, jaccard_neu=0.978, jaccard_pos=0.634, loss=0.0195]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.704, jaccard_neg=0.528, jaccard_neu=0.974, jaccard_pos=0.514, loss=0.0283]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.704193313653621\n","Jaccard_neu = 0.9742242602045511\n","Jaccard_pos = 0.5135798805519286\n","Jaccard_neg = 0.5282280424961713\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.19it/s, jaccard=0.784, jaccard_neg=0.667, jaccard_neu=0.978, jaccard_pos=0.64, loss=0.019]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.706, jaccard_neg=0.528, jaccard_neu=0.974, jaccard_pos=0.519, loss=0.0284]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7060281056110576\n","Jaccard_neu = 0.974282053041111\n","Jaccard_pos = 0.5190589406340586\n","Jaccard_neg = 0.5284579615610224\n","Saving positive model with jaccard of 0.5190589406340586!\n","Fold no 4:\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training....\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:40<00:00,  2.14it/s, jaccard=0.492, jaccard_neg=0.318, jaccard_neu=0.75, jaccard_pos=0.315, loss=0.0682]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.68, jaccard_neg=0.475, jaccard_neu=0.974, jaccard_pos=0.485, loss=0.0301]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6802027589875906\n","Jaccard_neu = 0.9736319590569253\n","Jaccard_pos = 0.48524784034534124\n","Jaccard_neg = 0.4752741929558008\n","Saving neutral model with jaccard of 0.9736319590569253!\n","Saving negative model with jaccard of 0.4752741929558008!\n","Saving positive model with jaccard of 0.48524784034534124!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:39<00:00,  2.16it/s, jaccard=0.685, jaccard_neg=0.487, jaccard_neu=0.975, jaccard_pos=0.488, loss=0.0287]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.7, jaccard_neg=0.512, jaccard_neu=0.974, jaccard_pos=0.517, loss=0.0265]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7003899320703747\n","Jaccard_neu = 0.9736724228248194\n","Jaccard_pos = 0.5170636169274839\n","Jaccard_neg = 0.5119125103385895\n","Saving neutral model with jaccard of 0.9736724228248194!\n","Saving negative model with jaccard of 0.5119125103385895!\n","Saving positive model with jaccard of 0.5170636169274839!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.712, jaccard_neg=0.536, jaccard_neu=0.976, jaccard_pos=0.528, loss=0.0254]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.705, jaccard_neg=0.517, jaccard_neu=0.974, jaccard_pos=0.526, loss=0.0262]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7047140767940149\n","Jaccard_neu = 0.9736904160692962\n","Jaccard_pos = 0.5260057115296971\n","Jaccard_neg = 0.5170247034444109\n","Saving neutral model with jaccard of 0.9736904160692962!\n","Saving negative model with jaccard of 0.5170247034444109!\n","Saving positive model with jaccard of 0.5260057115296971!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.729, jaccard_neg=0.569, jaccard_neu=0.976, jaccard_pos=0.553, loss=0.0237]\n","100%|██████████| 55/55 [00:12<00:00,  4.39it/s, jaccard=0.706, jaccard_neg=0.52, jaccard_neu=0.973, jaccard_pos=0.53, loss=0.0268]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7062618813928739\n","Jaccard_neu = 0.973438419536712\n","Jaccard_pos = 0.5297348701127477\n","Jaccard_neg = 0.5201616433832068\n","Saving negative model with jaccard of 0.5201616433832068!\n","Saving positive model with jaccard of 0.5297348701127477!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:37<00:00,  2.18it/s, jaccard=0.749, jaccard_neg=0.605, jaccard_neu=0.977, jaccard_pos=0.582, loss=0.0221]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.707, jaccard_neg=0.521, jaccard_neu=0.973, jaccard_pos=0.534, loss=0.0268]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7071444269890356\n","Jaccard_neu = 0.9726176043123104\n","Jaccard_pos = 0.5340364816074451\n","Jaccard_neg = 0.5206361762231896\n","Saving negative model with jaccard of 0.5206361762231896!\n","Saving positive model with jaccard of 0.5340364816074451!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.763, jaccard_neg=0.628, jaccard_neu=0.977, jaccard_pos=0.605, loss=0.0208]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.707, jaccard_neg=0.519, jaccard_neu=0.973, jaccard_pos=0.537, loss=0.0279]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7070066886731922\n","Jaccard_neu = 0.972572384220604\n","Jaccard_pos = 0.5366063093804964\n","Jaccard_neg = 0.5192582578194073\n","Saving positive model with jaccard of 0.5366063093804964!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.776, jaccard_neg=0.653, jaccard_neu=0.978, jaccard_pos=0.623, loss=0.0198]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.706, jaccard_neg=0.52, jaccard_neu=0.972, jaccard_pos=0.533, loss=0.0281]\n","  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.706112960799753\n","Jaccard_neu = 0.9721951242274448\n","Jaccard_pos = 0.5327678310707157\n","Jaccard_neg = 0.5195043298178196\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.784, jaccard_neg=0.671, jaccard_neu=0.978, jaccard_pos=0.632, loss=0.0193]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.704, jaccard_neg=0.517, jaccard_neu=0.972, jaccard_pos=0.529, loss=0.0282]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7040751938954679\n","Jaccard_neu = 0.9723087815791198\n","Jaccard_pos = 0.5288570218541659\n","Jaccard_neg = 0.5166012077033167\n","Fold no 5:\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/344 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training....\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:41<00:00,  2.14it/s, jaccard=0.492, jaccard_neg=0.33, jaccard_neu=0.733, jaccard_pos=0.325, loss=0.0675]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.684, jaccard_neg=0.477, jaccard_neu=0.979, jaccard_pos=0.491, loss=0.0294]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6844545700464836\n","Jaccard_neu = 0.97887999329448\n","Jaccard_pos = 0.4914839337375082\n","Jaccard_neg = 0.47724880188889396\n","Saving neutral model with jaccard of 0.97887999329448!\n","Saving negative model with jaccard of 0.47724880188889396!\n","Saving positive model with jaccard of 0.4914839337375082!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:39<00:00,  2.15it/s, jaccard=0.693, jaccard_neg=0.501, jaccard_neu=0.974, jaccard_pos=0.501, loss=0.0278]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.694, jaccard_neg=0.504, jaccard_neu=0.978, jaccard_pos=0.497, loss=0.0272]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6936449243888441\n","Jaccard_neu = 0.9784227210227453\n","Jaccard_pos = 0.4973639492502335\n","Jaccard_neg = 0.5043973023204681\n","Saving negative model with jaccard of 0.5043973023204681!\n","Saving positive model with jaccard of 0.4973639492502335!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.713, jaccard_neg=0.539, jaccard_neu=0.975, jaccard_pos=0.53, loss=0.0254]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.696, jaccard_neg=0.506, jaccard_neu=0.978, jaccard_pos=0.505, loss=0.0265]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6960799682738757\n","Jaccard_neu = 0.9784340280499983\n","Jaccard_pos = 0.5052971552762118\n","Jaccard_neg = 0.5055346725447372\n","Saving negative model with jaccard of 0.5055346725447372!\n","Saving positive model with jaccard of 0.5052971552762118!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:39<00:00,  2.16it/s, jaccard=0.73, jaccard_neg=0.571, jaccard_neu=0.975, jaccard_pos=0.556, loss=0.0237]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.697, jaccard_neg=0.506, jaccard_neu=0.978, jaccard_pos=0.511, loss=0.0269]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6973962330389161\n","Jaccard_neu = 0.9781118226972627\n","Jaccard_pos = 0.5105310260249287\n","Jaccard_neg = 0.5060971639614384\n","Saving negative model with jaccard of 0.5060971639614384!\n","Saving positive model with jaccard of 0.5105310260249287!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.16it/s, jaccard=0.743, jaccard_neg=0.597, jaccard_neu=0.975, jaccard_pos=0.574, loss=0.0224]\n","100%|██████████| 55/55 [00:12<00:00,  4.41it/s, jaccard=0.699, jaccard_neg=0.515, jaccard_neu=0.978, jaccard_pos=0.511, loss=0.0269]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.6993394674349536\n","Jaccard_neu = 0.9776489419524148\n","Jaccard_pos = 0.5105842045043012\n","Jaccard_neg = 0.5147076078753612\n","Saving negative model with jaccard of 0.5147076078753612!\n","Saving positive model with jaccard of 0.5105842045043012!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:38<00:00,  2.17it/s, jaccard=0.756, jaccard_neg=0.62, jaccard_neu=0.976, jaccard_pos=0.592, loss=0.0213]\n","100%|██████████| 55/55 [00:12<00:00,  4.43it/s, jaccard=0.7, jaccard_neg=0.514, jaccard_neu=0.978, jaccard_pos=0.513, loss=0.0271]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7003293967119162\n","Jaccard_neu = 0.9777314119479562\n","Jaccard_pos = 0.5128542219986277\n","Jaccard_neg = 0.5140033996073727\n","Saving positive model with jaccard of 0.5128542219986277!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:39<00:00,  2.16it/s, jaccard=0.768, jaccard_neg=0.641, jaccard_neu=0.976, jaccard_pos=0.612, loss=0.0204]\n","100%|██████████| 55/55 [00:12<00:00,  4.40it/s, jaccard=0.701, jaccard_neg=0.51, jaccard_neu=0.977, jaccard_pos=0.517, loss=0.0274]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7006424216624577\n","Jaccard_neu = 0.9773548452642384\n","Jaccard_pos = 0.516963494204593\n","Jaccard_neg = 0.5097471047929736\n","Saving positive model with jaccard of 0.516963494204593!\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 344/344 [02:39<00:00,  2.16it/s, jaccard=0.773, jaccard_neg=0.65, jaccard_neu=0.977, jaccard_pos=0.62, loss=0.02]\n","100%|██████████| 55/55 [00:12<00:00,  4.42it/s, jaccard=0.702, jaccard_neg=0.512, jaccard_neu=0.977, jaccard_pos=0.52, loss=0.0277]\n"],"name":"stderr"},{"output_type":"stream","text":["Jaccard = 0.7024671046085513\n","Jaccard_neu = 0.9772288665713563\n","Jaccard_pos = 0.5204993908765064\n","Jaccard_neg = 0.512442814596404\n","Saving positive model with jaccard of 0.5204993908765064!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8iZnM5lLVyUY","colab_type":"code","outputId":"0e9faefd-c167-4198-c405-73e97c2646f4","executionInfo":{"status":"ok","timestamp":1590511838673,"user_tz":-120,"elapsed":7001529,"user":{"displayName":"phu hien nguyen","photoUrl":"","userId":"00373885389146987088"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["print('Jaccard score')\n","print(all_scores, np.mean(all_scores))\n","print('Neutral score')\n","print(score_neu, np.mean(score_neu))\n","print('Negative score')\n","print(score_neg, np.mean(score_neg))\n","print('Positive score')\n","print(score_pos, np.mean(score_pos)) "],"execution_count":19,"outputs":[{"output_type":"stream","text":["Jaccard score\n","[0.7042680416445792, 0.7106379187504039, 0.7062949624224804, 0.7071444269890356, 0.7024671046085513] 0.7061624908830101\n","Neutral score\n","[0.9731274241987712, 0.9750525690816386, 0.9761117968191045, 0.9736904160692962, 0.97887999329448] 0.9753724398926582\n","Negative score\n","[0.5295553918361091, 0.5311770650198643, 0.5321096654464132, 0.5206361762231896, 0.5147076078753612] 0.5256371812801874\n","Positive score\n","[0.5165439472309954, 0.5315587470878916, 0.5190589406340586, 0.5366063093804964, 0.5204993908765064] 0.5248534670419895\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oZMiiAmkV3EZ","colab_type":"code","outputId":"25e58688-3490-4478-c891-fa92eb27a099","executionInfo":{"status":"ok","timestamp":1590511838674,"user_tz":-120,"elapsed":7001041,"user":{"displayName":"phu hien nguyen","photoUrl":"","userId":"00373885389146987088"}},"colab":{"base_uri":"https://localhost:8080/","height":979}},"source":["train['predictions'] = predictions\n","train.loc[(train.sentiment == 'negative') | (train.sentiment=='positive')][:30]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","      <th>predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","      <td>Sooo SAD</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","      <td>bullying me...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","      <td>leave me alone</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","      <td>****,</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6e0c6d75b1</td>\n","      <td>2am feedings for the baby are fun when he is a...</td>\n","      <td>fun</td>\n","      <td>positive</td>\n","      <td>fun</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fc2cbefa9d</td>\n","      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n","      <td>Wow... u just became cooler.</td>\n","      <td>positive</td>\n","      <td>Wow...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>16fab9f95b</td>\n","      <td>I really really like the song Love Story by Ta...</td>\n","      <td>like</td>\n","      <td>positive</td>\n","      <td>I really really like</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>74a76f6e0a</td>\n","      <td>My Sharpie is running DANGERously low on ink</td>\n","      <td>DANGERously</td>\n","      <td>negative</td>\n","      <td>running DANGERously low on ink</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>04dd1d2e34</td>\n","      <td>i want to go to music tonight but i lost my vo...</td>\n","      <td>lost</td>\n","      <td>negative</td>\n","      <td>lost</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>8a939bfb59</td>\n","      <td>Uh oh, I am sunburned</td>\n","      <td>Uh oh, I am sunburned</td>\n","      <td>negative</td>\n","      <td>sunburned</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>3440297f8b</td>\n","      <td>S`ok, trying to plot alternatives as we speak...</td>\n","      <td>*sigh*</td>\n","      <td>negative</td>\n","      <td>*sigh*</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>919fa93391</td>\n","      <td>i`ve been sick for the past few days  and thus...</td>\n","      <td>sick</td>\n","      <td>negative</td>\n","      <td>sick for the past few days and thus, my hair ...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>af3fed7fc3</td>\n","      <td>is back home now      gonna miss every one</td>\n","      <td>onna</td>\n","      <td>negative</td>\n","      <td>miss</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>e48b0b8a23</td>\n","      <td>Playing Ghost Online is really interesting. Th...</td>\n","      <td>interesting.</td>\n","      <td>positive</td>\n","      <td>really interesting.</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>e00c6ef376</td>\n","      <td>the free fillin` app on my ipod is fun, im add...</td>\n","      <td>the free fillin` app on my ipod is fun, im add...</td>\n","      <td>positive</td>\n","      <td>fun,</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>852edc3769</td>\n","      <td>I`m sorry.</td>\n","      <td>I`m sorry.</td>\n","      <td>negative</td>\n","      <td>I`m sorry.</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>bdc32ea43c</td>\n","      <td>On the way to Malaysia...no internet access to...</td>\n","      <td>.no internet</td>\n","      <td>negative</td>\n","      <td>no internet access</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>6ce4a4954b</td>\n","      <td>juss came backk from Berkeleyy ; omg its madd ...</td>\n","      <td>fun</td>\n","      <td>positive</td>\n","      <td>add fun</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>d22e6d40a7</td>\n","      <td>Went to sleep and there is a power cut in Noid...</td>\n","      <td>Power back up not working too</td>\n","      <td>negative</td>\n","      <td>not working too</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>d33f811375</td>\n","      <td>I`m going home now. Have you seen my new twitt...</td>\n","      <td>Quite....heavenly</td>\n","      <td>positive</td>\n","      <td>Quite....heavenly</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>7d8c4c11e4</td>\n","      <td>i hope unni will make the audition . fighting ...</td>\n","      <td>hope</td>\n","      <td>positive</td>\n","      <td>hope</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>1c31703aef</td>\n","      <td>If it is any consolation I got my BMI tested ...</td>\n","      <td>well so much for being unhappy for about 10 mi...</td>\n","      <td>negative</td>\n","      <td>unhappy</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>2dc51711bc</td>\n","      <td>That`s very funny.  Cute kids.</td>\n","      <td>funny.</td>\n","      <td>positive</td>\n","      <td>That`s very funny. Cute</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>2724775d6b</td>\n","      <td>Born and raised in NYC and living in Texas for...</td>\n","      <td>miss</td>\n","      <td>negative</td>\n","      <td>miss</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>4b61dffbeb</td>\n","      <td>i`m soooooo sleeeeepy!!! the last day o` schoo...</td>\n","      <td>soooooo sleeeeepy!!!</td>\n","      <td>negative</td>\n","      <td>....sniffle....</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>2863f435bd</td>\n","      <td>A little happy for the wine jeje ok it`sm my f...</td>\n","      <td>A little happy fo</td>\n","      <td>positive</td>\n","      <td>i love</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>fab6b7d16c</td>\n","      <td>im an avid fan of **** magazine and i love you...</td>\n","      <td>avid fan of</td>\n","      <td>positive</td>\n","      <td>i love</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>c77717b103</td>\n","      <td>I love to! But I`m only available from 5pm.  ...</td>\n","      <td>I love to!</td>\n","      <td>positive</td>\n","      <td>love to!</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>ddf296dffa</td>\n","      <td>egh blah and boooooooooooo i dunno wanna go to...</td>\n","      <td>SUCKKKKKK</td>\n","      <td>negative</td>\n","      <td>SUCKKKKKK Im a drunk mess!</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>3d9d4b0b55</td>\n","      <td>i donbt like to peel prawns, i also dont like ...</td>\n","      <td>dont like go</td>\n","      <td>negative</td>\n","      <td>i donbt like to peel prawns, i also dont like...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        textID  ...                                        predictions\n","1   549e992a42  ...                                           Sooo SAD\n","2   088c60f138  ...                                     bullying me...\n","3   9642c003ef  ...                                     leave me alone\n","4   358bd9e861  ...                                              ****,\n","6   6e0c6d75b1  ...                                                fun\n","9   fc2cbefa9d  ...                                             Wow...\n","11  16fab9f95b  ...                               I really really like\n","12  74a76f6e0a  ...                     running DANGERously low on ink\n","13  04dd1d2e34  ...                                               lost\n","15  8a939bfb59  ...                                          sunburned\n","16  3440297f8b  ...                                             *sigh*\n","17  919fa93391  ...   sick for the past few days and thus, my hair ...\n","18  af3fed7fc3  ...                                               miss\n","21  e48b0b8a23  ...                                really interesting.\n","25  e00c6ef376  ...                                               fun,\n","26  852edc3769  ...                                         I`m sorry.\n","27  bdc32ea43c  ...                                 no internet access\n","28  6ce4a4954b  ...                                            add fun\n","29  d22e6d40a7  ...                                    not working too\n","30  d33f811375  ...                                  Quite....heavenly\n","31  7d8c4c11e4  ...                                               hope\n","32  1c31703aef  ...                                            unhappy\n","33  2dc51711bc  ...                            That`s very funny. Cute\n","36  2724775d6b  ...                                               miss\n","38  4b61dffbeb  ...                                    ....sniffle....\n","39  2863f435bd  ...                                             i love\n","41  fab6b7d16c  ...                                             i love\n","44  c77717b103  ...                                           love to!\n","46  ddf296dffa  ...                         SUCKKKKKK Im a drunk mess!\n","48  3d9d4b0b55  ...   i donbt like to peel prawns, i also dont like...\n","\n","[30 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":20}]}]}